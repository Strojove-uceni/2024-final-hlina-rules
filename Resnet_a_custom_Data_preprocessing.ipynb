{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vsG-D6P6Sx8hmAnO6qPHhK251NGaXUcX",
      "authorship_tag": "ABX9TyOsL+DlHpEgidQJuoEX57Ak",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strojove-uceni/2024-final-hlina-rules/blob/main/Resnet_a_custom_Data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "CNBQJ1XlYsNk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97f7b64c-12fb-4bd8-9f3d-047926799bd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch [1/10], Loss: 4.309817314147949\n",
            "Epoch [2/10], Loss: 1.02295982837677\n",
            "Epoch [3/10], Loss: 0.22139587998390198\n",
            "Epoch [4/10], Loss: 0.06105317175388336\n",
            "Epoch [5/10], Loss: 0.019830303266644478\n",
            "Epoch [6/10], Loss: 0.007371401414275169\n",
            "Epoch [7/10], Loss: 0.0029464815743267536\n",
            "Epoch [8/10], Loss: 0.0016646489966660738\n",
            "Epoch [9/10], Loss: 0.0007822939660400152\n",
            "Epoch [10/10], Loss: 0.0004088669375050813\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import random\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#Data preprocessing\n",
        "class RandomRotate:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, image):\n",
        "        transform = transforms.RandomRotation(degrees=(-10,10))\n",
        "        return transform(image)\n",
        "\n",
        "\n",
        "class RandomPerspectiveTransform:    #applied with the 0.1 probability\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, image):\n",
        "        transform = transforms.RandomPerspective(distortion_scale=0.5, p=1.0)\n",
        "        if random.random() < 0.1:\n",
        "            return transform(image)\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "class CenteredCrop:\n",
        "    def __init__(self, crop_size=100, output_size=320):\n",
        "        self.crop_size = crop_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, image, nozzle_x, nozzle_y):\n",
        "        # Calculate crop box boundaries\n",
        "        left = max(nozzle_x - self.crop_size // 2, 0)\n",
        "        upper = max(nozzle_y - self.crop_size // 2, 0)\n",
        "        right = min(nozzle_x + self.crop_size // 2, image.width)\n",
        "        lower = min(nozzle_y + self.crop_size // 2, image.height)\n",
        "\n",
        "        cropped_img = image.crop((left, upper, right, lower))\n",
        "        resized_img = cropped_img.resize((self.output_size, self.output_size), Image.Resampling.LANCZOS)\n",
        "\n",
        "        return resized_img\n",
        "\n",
        "\n",
        "class RandomCrop:\n",
        "    def __init__(self, output_size=224):\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, image):\n",
        "        h, w = image.size[1], image.size[0]  # the image will be after 320x320 reshaping so they are equal\n",
        "        scale_factor = random.uniform(0.9, 1.0)\n",
        "        crop_size = int(h*scale_factor)\n",
        "        max_top = h - crop_size\n",
        "        max_left = w - crop_size\n",
        "        top = random.randint(0, max_top)\n",
        "        left = random.randint(0, max_left)\n",
        "        cropped = image.crop((left, top, left + crop_size, top + crop_size))\n",
        "        resized_cropped = cropped.resize((self.output_size, self.output_size), Image.Resampling.LANCZOS)\n",
        "        return resized_cropped\n",
        "\n",
        "\n",
        "class HorizontalFlipColorJitter:   #apply with probability 0.5\n",
        "    def __init__(self):\n",
        "        self.brightness = 0.1\n",
        "        self.contrast = 0.1\n",
        "        self.saturation = 0.1\n",
        "        self.hue = 0.1\n",
        "\n",
        "    def __call__(self, image):\n",
        "        flipped = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        color_jitter = transforms.ColorJitter(\n",
        "            brightness = self.brightness,\n",
        "            contrast= self.contrast,\n",
        "            saturation=self.saturation,\n",
        "            hue=self.hue\n",
        "        )\n",
        "        jittered_image = color_jitter(flipped)\n",
        "\n",
        "        if random.random() < 0.5:\n",
        "            return jittered_image\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "\n",
        "class TransformPipeline:\n",
        "    def __init__(self, pipeline):\n",
        "        self.pipeline = pipeline\n",
        "\n",
        "    def __call__(self, image, **kwargs):\n",
        "        for job in self.pipeline:\n",
        "            if isinstance(job, CenteredCrop):\n",
        "                image = job(image, kwargs['nozzle_x'], kwargs['nozzle_y'])\n",
        "            else:\n",
        "                image = job(image)\n",
        "        return image\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, nozzle_coords, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.nozzle_coords = nozzle_coords\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        nozzle_x, nozzle_y = self.nozzle_coords[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            if isinstance(self.transform, TransformPipeline):\n",
        "                image = self.transform(image, nozzle_x=nozzle_x, nozzle_y=nozzle_y)\n",
        "            else:\n",
        "                image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Prepare the train data\n",
        "transform_pipeline = TransformPipeline([\n",
        "    RandomRotate(),\n",
        "    RandomPerspectiveTransform(),\n",
        "    CenteredCrop(crop_size=100, output_size=320),\n",
        "    RandomCrop(output_size=224),\n",
        "    HorizontalFlipColorJitter(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "path = '/content/image-6.jpg'\n",
        "\n",
        "train_image_paths = [path]  # List of image paths\n",
        "train_labels = [[1,1,1,1]] # List of train labels\n",
        "train_nozzle_coords = [(531,554)]  # List of nozzle coordinates\n",
        "\n",
        "train_dataset = CustomDataset(image_paths=train_image_paths, labels=train_labels, nozzle_coords=train_nozzle_coords, transform=transform_pipeline)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "########################################################################################################\n",
        "\n",
        "# PRETRAINED RESNET\n",
        "\n",
        "########################################################################################################\n",
        "\n",
        "\n",
        "# Load the pretrained ResNet model\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the final layers to be able to assess the four criteria\n",
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(CustomResNet, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the original fully connected layer\n",
        "\n",
        "        #output layer for each of the 4 criteria - three outputs for each criterion: 'high', 'low', 'good'\n",
        "        self.fc1 = nn.Linear(2048, 3)\n",
        "        self.fc2 = nn.Linear(2048, 3)\n",
        "        self.fc3 = nn.Linear(2048, 3)\n",
        "        self.fc4 = nn.Linear(2048, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        out1 = self.fc1(x)\n",
        "        out2 = self.fc2(x)\n",
        "        out3 = self.fc3(x)\n",
        "        out4 = self.fc4(x)\n",
        "        return out1, out2, out3, out4\n",
        "\n",
        "# Create instance of the custom model\n",
        "model = CustomResNet(resnet)\n",
        "\n",
        "lrn_rate = 0.001 #set learning rate\n",
        "\n",
        "# loss function and optimizer\n",
        "loss_f = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lrn_rate)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "\n",
        "        labels1, labels2, labels3, labels4 = labels\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs1, outputs2, outputs3, outputs4 = model(inputs)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss1 = loss_f(outputs1, labels1)\n",
        "        loss2 = loss_f(outputs2, labels2)\n",
        "        loss3 = loss_f(outputs3, labels3)\n",
        "        loss4 = loss_f(outputs4, labels4)\n",
        "        loss = loss1 + loss2 + loss3 + loss4\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'custom_resnet.pth')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the test data\n",
        "to_tensor_pipeline = TransformPipeline([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_image_paths = ['/content/image-15.jpg']  # List of test image paths\n",
        "test_labels = [[1,1,1,1]]  # List of test labels for each criterion\n",
        "test_nozzle_coords = [(531, 554)]  # List of test nozzle coordinates\n",
        "\n",
        "test_dataset = CustomDataset(image_paths=test_image_paths, labels=test_labels, nozzle_coords=test_nozzle_coords, transform=to_tensor_pipeline)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Evaluation loop\n",
        "correct1, correct2, correct3, correct4 = 0, 0, 0, 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        #labels1, labels2, labels3, labels4 = labels[:, 0], labels[:, 1], labels[:, 2], labels[:, 3]\n",
        "        labels1, labels2, labels3, labels4 = labels[0], labels[1], labels[2], labels[3]\n",
        "        outputs1, outputs2, outputs3, outputs4 = model(inputs)\n",
        "        _, predicted1 = torch.max(outputs1, 1)\n",
        "        _, predicted2 = torch.max(outputs2, 1)\n",
        "        _, predicted3 = torch.max(outputs3, 1)\n",
        "        _, predicted4 = torch.max(outputs4, 1)\n",
        "        total += labels1.size(0)\n",
        "        correct1 += (predicted1 == labels1).sum().item()\n",
        "        correct2 += (predicted2 == labels2).sum().item()\n",
        "        correct3 += (predicted3 == labels3).sum().item()\n",
        "        correct4 += (predicted4 == labels4).sum().item()\n",
        "\n",
        "print(f'Accuracy for criterion 1: {100 * correct1 / total}%')\n",
        "print(f'Accuracy for criterion 2: {100 * correct2 / total}%')\n",
        "print(f'Accuracy for criterion 3: {100 * correct3 / total}%')\n",
        "print(f'Accuracy for criterion 4: {100 * correct4 / total}%')"
      ],
      "metadata": {
        "id": "jihwFHpB8qdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35bec3fe-7b9b-46d7-f054-f377898848e7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for criterion 1: 100.0%\n",
            "Accuracy for criterion 2: 100.0%\n",
            "Accuracy for criterion 3: 100.0%\n",
            "Accuracy for criterion 4: 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fcWC_mbCt2q",
        "outputId": "0d7b420b-3692-4d7a-fd85-5842fb7ff04b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "True\n"
          ]
        }
      ]
    }
  ]
}