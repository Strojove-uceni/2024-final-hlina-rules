{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strojove-uceni/2024-final-hlina-rules/blob/main/SU2_kaggledata_revize(haha)Petr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmI-oESfLihh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import cv2\n",
        "from torch.utils.data import Dataset\n",
        "from os import sendfile\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "from torch.utils.data import DataLoader\n",
        "import torchmetrics\n",
        "from torch import nn\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_Sxy3DGkOMn"
      },
      "outputs": [],
      "source": [
        "TEST_SIZE = 0.2\n",
        "H, W = 224, 224\n",
        "BATCH_SIZE = 2\n",
        "TRAIN_SIZE = 0.6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t554EwbbZ8St",
        "outputId": "09c362a3-7525-4ee1-bfb8-190ebeb96d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8G662OfL6g8"
      },
      "outputs": [],
      "source": [
        "class RandomCrop():\n",
        "  def __init__(self, h, w):\n",
        "    self.h = h\n",
        "    self.w = w\n",
        "\n",
        "  def __call__(self, x):\n",
        "    h, w, _ = x.shape\n",
        "    h = h - self.h\n",
        "    w - w - self.w\n",
        "    H = np.random.randint(0,h,1)[0]\n",
        "    W = np.random.randint(0,w,1)[0]\n",
        "    x = x[H:H + self.h, W: W + self.w, :]\n",
        "    assert x.shape == (self.h, self.w, 3)\n",
        "    return x\n",
        "\n",
        "class Resize():\n",
        "  def __init__(self, w, h, interpolation):\n",
        "    self.w= w\n",
        "    self.h = h\n",
        "    self.interpolation = interpolation\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return cv2.resize(x, (self.h, self.w), interpolation = self.interpolation)\n",
        "\n",
        "class Rescale():\n",
        "  def __init__(self,x, max_value):\n",
        "    self.max_value = max_value\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return x/self.max_value\n",
        "\n",
        "class TransformPipeline():\n",
        "  def __init__(self, pipeline):\n",
        "    self.pipeline = pipeline\n",
        "\n",
        "  def __call__(self, x):\n",
        "    for job in self.pipeline:\n",
        "      x = job(x)\n",
        "    return x\n",
        "\n",
        "class AdjustDimension():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def __call__(self, x):\n",
        "    return np.transpose(x, (2,0,1))\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, data, device, xPipe=None):\n",
        "    self.data = data\n",
        "    self.xtp = xPipe\n",
        "    self.device = device\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    x,y = self.data[idx]\n",
        "    return torch.as_tensor(\n",
        "            self.xtp(cv2.imread(x)), dtype=torch.float32, device=self.device\n",
        "        ), torch.as_tensor(y, dtype=torch.int64, device=self.device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PHpVeDMRiM8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfOPFU4xZ11Z"
      },
      "outputs": [],
      "source": [
        "bad = r'/content/drive/MyDrive/Vyzkumak/3Dprint_kaggle/defected'\n",
        "good = r'/content/drive/MyDrive/Vyzkumak/3Dprint_kaggle/no_defected'\n",
        "\n",
        "good_samples = []\n",
        "for img in os.listdir(good):\n",
        "    img_path = os.path.join(good, img)\n",
        "    good_samples.append([img_path, 0])\n",
        "\n",
        "bad_samples = []\n",
        "for img in os.listdir(bad):\n",
        "    img_path = os.path.join(bad, img)\n",
        "    bad_samples.append([img_path, 1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fr6k6DdmkE3D"
      },
      "outputs": [],
      "source": [
        "good_samples = shuffle(good_samples)\n",
        "good_len = len(good_samples)\n",
        "bad_samples = shuffle(bad_samples)\n",
        "bad_len = len(bad_samples)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rbv1EFPmksMk"
      },
      "outputs": [],
      "source": [
        "test_good, train_good = good_samples[:int(good_len * TEST_SIZE)], good_samples[int(good_len * TEST_SIZE):int(good_len*(TEST_SIZE+TRAIN_SIZE))] #uprava pro validacni data\n",
        "val_good = good_samples[int(good_len*(TEST_SIZE+TRAIN_SIZE)):]\n",
        "test_bad, train_bad, val_bad = bad_samples[:int(bad_len * TEST_SIZE)], bad_samples[int(bad_len * TEST_SIZE):int(good_len*(TEST_SIZE+TRAIN_SIZE)]\n",
        "val_good = bad_samples[int(bad_len*(TEST_SIZE+TRAIN_SIZE)):]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97zrKeHflTrb"
      },
      "outputs": [],
      "source": [
        "train_data = train_good + train_bad\n",
        "test_data = test_good + test_bad\n",
        "val_data = val_good + val_bad\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYPwz9M6mA_W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nKBbyFdmKqL"
      },
      "outputs": [],
      "source": [
        "train_tfx_pipeline = TransformPipeline([\n",
        "    Resize(H, W, cv2.INTER_AREA), Rescale(255, 2), AdjustDimension()\n",
        "])\n",
        "\n",
        "train_dataset = CustomDataset(train_data, device, train_tfx_pipeline)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "test_dataset = CustomDataset(test_data, device, train_tfx_pipeline)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "val_dataset = CustomDataset(val_data, device, train_tfx_pipeline)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYvAs4yMmh5l",
        "outputId": "68df49fb-2dff-4c96-9137-29410351b5a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.5.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.5.2-py3-none-any.whl (891 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.4/891.4 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.8 torchmetrics-1.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uj-3R0q6rLIp"
      },
      "outputs": [],
      "source": [
        "ModeDict = {\n",
        "            'min': lambda t2, t1, threshold=0: t1-t2 > threshold,\n",
        "            'max': lambda t2, t1, threshold=0: t2-t1 > threshold\n",
        "           }\n",
        "# Create Callable Object\n",
        "class EarlyStopping:\n",
        "    def __init__(self,\n",
        "                 monitor : str = 'val_loss',\n",
        "                 patience : int = 0,\n",
        "                 min_delta : float = 0.0,\n",
        "                 mode : str = 'min',\n",
        "                 restore : bool = True):\n",
        "        assert patience >= 0\n",
        "        assert mode in ModeDict.keys()\n",
        "\n",
        "        self._monitor = monitor.lower()\n",
        "        self._patience = patience\n",
        "        self._restore = restore\n",
        "        self._delta = min_delta\n",
        "        self._mode = ModeDict[mode]\n",
        "        self._baseline = None\n",
        "        self.__counter = 0\n",
        "\n",
        "    def __call__(self, **kwargs):\n",
        "        model = kwargs['model']\n",
        "        optimizer = kwargs['optimizer']\n",
        "        history = kwargs['history']\n",
        "        epoch = len(history['loss'])\n",
        "        assert self._monitor in history.keys(), f'{self._monitor} not found'\n",
        "        present = history[self._monitor][-1]\n",
        "        satisfied, keep_training = True, True\n",
        "        if self._baseline is None:\n",
        "            self._baseline = present\n",
        "            # save checkpoint\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss':present\n",
        "            }, './checkpoint.pt')\n",
        "        else:\n",
        "            satisfied = self._mode(present, self._baseline, self._delta)\n",
        "            if satisfied:\n",
        "                print(f'{self._monitor} Updated: {present}')\n",
        "                self._baseline = present\n",
        "                self.__counter = 0\n",
        "                # save checkpoint\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss':present\n",
        "                }, './checkpoint.pt')\n",
        "            else:\n",
        "                self.__counter += 1\n",
        "                if self.__counter > self._patience:\n",
        "                    keep_training = False\n",
        "                    if self._restore:\n",
        "                        checkpoint = torch.load('./checkpoint.pt')\n",
        "                        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        return keep_training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pft6C4S6rtGt"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, testloader, model, **conf):\n",
        "    metrics = conf['metrics']\n",
        "    criterion = conf['criterion']\n",
        "    regularizers = conf['regularizers']\n",
        "    callbacks = conf['callbacks']\n",
        "\n",
        "    optimizer = conf['optimizer']\n",
        "    max_iter = conf['max_iter']\n",
        "    device = conf['device']\n",
        "\n",
        "    history = dict()\n",
        "    history['loss'] = []\n",
        "    history['val_loss'] = []\n",
        "    for m in metrics:\n",
        "        history[m['name']] = []\n",
        "        history[f'val_{m[\"name\"]}'] = []\n",
        "\n",
        "    for itr in range(max_iter):\n",
        "        model.train()\n",
        "\n",
        "        real_time = dict()\n",
        "        real_time['loss'] = []\n",
        "        for m in metrics:\n",
        "            real_time[m['name']] = []\n",
        "        for _, (X, y) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            #X.to(device)\n",
        "            #y.to(device)\n",
        "            # Compute prediction and loss\n",
        "            pred = model(X)\n",
        "            pred_labels = torch.argmax(pred, dim=1)\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "\n",
        "            for regularizer in regularizers:\n",
        "                loss += regularizer(model.parameters())\n",
        "\n",
        "            real_time['loss'].append(loss.item())\n",
        "            for m in metrics:\n",
        "                real_time[m['name']].append(m['fn'](pred_labels, y).item())\n",
        "\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # compute metrics\n",
        "        history['loss'].append(np.mean(real_time['loss']))\n",
        "        epoch_loss = history['loss'][-1]\n",
        "        print(f\"\\n[{itr:>5d}/{max_iter:>5d}]\\tLoss: {epoch_loss:>4f}\\t\")\n",
        "\n",
        "        for m in metrics:\n",
        "            key = m['name']\n",
        "            value = np.mean(real_time[m['name']])\n",
        "            history[key].append(value)\n",
        "            print(f\"{key}: {value:>4f}\", end=' ')\n",
        "\n",
        "        # validation\n",
        "        model.eval()\n",
        "        val_metrics = dict()\n",
        "        val_metrics['val_loss'] = []\n",
        "        for m in metrics:\n",
        "            val_metrics[m['name']] = []\n",
        "        with torch.no_grad():\n",
        "            for X, y in testloader:\n",
        "                #X.to(device)\n",
        "                #y.to(device)\n",
        "                pred = model(X)\n",
        "                loss = criterion(pred, y)\n",
        "                val_metrics['val_loss'].append(loss.item())\n",
        "                val_pred_labels = torch.argmax(pred, dim=1)\n",
        "                for m in metrics:\n",
        "                    val_metrics[m['name']].append(m['fn'](val_pred_labels, y).item())\n",
        "        print(f'\\nValidation : Loss: {np.mean(val_metrics[\"val_loss\"]):>4f}, ', end='')\n",
        "        history['val_loss'].append(np.mean(val_metrics[\"val_loss\"]))\n",
        "        for m in metrics:\n",
        "            key = f\"val_{m['name']}\"\n",
        "            value = np.mean(val_metrics[m['name']])\n",
        "            #history[key] = value\n",
        "            history[key].append(value) # bug fixes\n",
        "            print(f\"{key}: {value:>4f}\", end=' ')\n",
        "        # callbacks\n",
        "        break_training = False\n",
        "        for callback in callbacks:\n",
        "            if not callback(model=model, optimizer=optimizer, history=history):\n",
        "                break_training = True\n",
        "                break\n",
        "        if break_training:\n",
        "            print('Training end triggered by callback.')\n",
        "            break\n",
        "    return history\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_metrics(model, dataloader, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    for m in test_metrics:\n",
        "            test_metrics[m['name']] = []\n",
        "        with torch.no_grad():\n",
        "            for X, y in testloader:\n",
        "                #X.to(device)\n",
        "                #y.to(device)\n",
        "                pred = model(X)\n",
        "                test_pred_labels = torch.argmax(pred, dim=1)\n",
        "                for m in metrics:\n",
        "                    test_metrics[m['name']].append(m['fn'](val_pred_labels, y).item())\n",
        "    return {\n",
        "        test_metrics\n",
        "    }"
      ],
      "metadata": {
        "id": "fhCQjXzmipxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JISIJd_Ar6QL",
        "outputId": "d459b63a-9f83-4e31-ade4-44ae1908e65d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 1e-4\n",
        "# l1, l2 = 0., 0.\n",
        "EPOCHS = 100\n",
        "KERNELS = 64\n",
        "\n",
        "net = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False).to(device)\n",
        "net.fc = nn.Linear(512, 2)\n",
        "\n",
        "OPTIM = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "callbacks = [EarlyStopping(\"val_loss\", patience=10)]\n",
        "regularizers = []\n",
        "\n",
        "metrics = [\n",
        "    {\"name\": 'Accuracy', \"fn\": torchmetrics.Accuracy(task = \"binary\").to(device)},\n",
        "    {\"name\": 'Recall', \"fn\": torchmetrics.Recall(task=\"binary\").to(device)}\n",
        "]\n",
        "\n",
        "test_metrics = [\n",
        "    {\"name\": 'Accuracy', \"fn\": torchmetrics.Accuracy(task = \"binary\").to(device)},\n",
        "    {\"name\": 'Recall', \"fn\": torchmetrics.Recall(task=\"binary\").to(device)},\n",
        "    {'name': 'Precision', 'fn': torchmetrics.BinaryPrecision().to(device)},\n",
        "    {'name': 'f1', 'fn': torchmetrics.F1score(task = 'binary').to(device)}\n",
        "]´\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gA8Y6kksJxU",
        "outputId": "defce708-70dc-49f2-cb35-ea73ab1b357e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[    0/  100]\tLoss: 0.497797\t\n",
            "Accuracy: 0.756410 Recall: 0.594551 \n",
            "Validation : Loss: 0.063724, val_Accuracy: 0.993421 val_Recall: 0.993421 \n",
            "[    1/  100]\tLoss: 0.197502\t\n",
            "Accuracy: 0.925481 Recall: 0.691506 \n",
            "Validation : Loss: 0.107061, val_Accuracy: 0.980263 val_Recall: 0.980263 \n",
            "[    2/  100]\tLoss: 0.083482\t\n",
            "Accuracy: 0.975160 Recall: 0.729167 \n",
            "Validation : Loss: 0.091050, val_Accuracy: 0.986842 val_Recall: 0.986842 \n",
            "[    3/  100]\tLoss: 0.088647\t\n",
            "Accuracy: 0.968750 Recall: 0.717949 \n",
            "Validation : Loss: 0.086687, val_Accuracy: 0.986842 val_Recall: 0.986842 "
          ]
        }
      ],
      "source": [
        "hist = train_loop(train_loader,\n",
        "    val_loader,\n",
        "    net,\n",
        "    optimizer=OPTIM,\n",
        "    max_iter=EPOCHS,\n",
        "    metrics=metrics,\n",
        "    criterion=criterion,\n",
        "    regularizers=regularizers,\n",
        "    callbacks=callbacks,\n",
        "    device=device)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}